v0.4.3: Added different c_ratio for random projection
    1. modified random projection k_factor to c_ratio
    2. modified plot_robust_aggregation.py with fixed markers and colors


v0.4.2: Add real_cases.py
    1. Add real_cases.py
    2. Remove trim_ratio from medoid()


v0.4.1: Restructure the project


v0.4.0: Add new dataset: Sentiment140
    1. Add Sentiment140
    2. Add min_samples_per_client into dirichlet_split() to make sure each client at least has
        min_samples_per_client samples.


v0.3.9: Generated results for NSF on MNIST


v0.3.8: Generated results for NSF
    1. replication_neurips

v0.3.7: Generate synthetic results


v0.3.6: Rewrite robust aggregation


v0.3.5: Add more robust algorithms
    1. E.g., geometric_median, trimmed_mean
    2. Store common functions into base.py


v0.3.4: Try different attacks and Update Krum.py
    1. Add weighted version for each method in krum.py
    2. Rename Krum.py as robust_aggregation.py


v0.3.3: Update Krum.py and aggregate_cnns
    1. aggregate_cnns aggregate on all parameters, instead of each layer.
    2. update refined_Krum
    3. update median


v0.3.2: Add more byzantine attacks
    1. sign_flipping, model_poisoning, data poisoning


v0.3.1: Find good case that shows Krum is better than median on MNIST
    1. For benign clients: 2 clients with part of classes, 3 clients with IID
        For Byzantine clients: give model parameters large values.

v0.3.0: Add robust aggregation for FedCNN
    1. IID for each client
    2. Refined_Krum, Krum, weighted median, weighted mean

v0.2.9: FedCNN only
    1. Server aggregate clients gradients

v0.2.8: FedCNN with CGAN for generate data
    1. Server train CGAN
    2. Refined Krum
    3. FedCNN

v0.2.7: FedCNN with CGAN for generate data

v0.2.6: CGAN for generate data

v0.2.5: Add nn only with one step

v0.2.4: Add aes only

v0.2.3: Add vaes only

v0.2.2: Add MMD and GANs

v0.2.1: Add evaluate_ML

v0.2.0: Add individual vae for each class

v0.1.9: Add jaccard

v0.1.8: Update early_stopping and plot gnn training loss.

v0.1.7: Tune different parameters and add classical ML
   1. Add label_rate
   2. Add best model based on validation accuracy

v0.1.6: Add cosine

v0.1.5: Add early_stopping to federated GNN

v0.1.4: Add graph_lp (graph link predictor) to predict edges between nodes

v0.1.3: Add graph_edge (a binary classifier) to predict edges between nodes

v0.1.2: Add more baseline models

v0.1.1: Update shared_test_set on all clients using the fixed pretrained_CNN

v0.1.0: Add 'shakespeare' and reddit dataset

v0.0.9-1: Fixed bugs after adding Sentiment140 dataset


v0.0.9: Add Sentiment140 data from Kaggle

1. https://www.kaggle.com/datasets/kazanova/sentiment140/data
It only has 2 labels.


v0.0.8: LEAF Shakespeare dataset preprocessing (LEAF dataset)

1. The url for shakespeare dataset changed
    1) from http to https
    2) from old to old/old
#wget http://www.gutenberg.org/files/100/old/1994-01-100.zip
curl -v -L -O https://www.gutenberg.org/files/100/old/old/1994-01-100.zip

2. Copy data/utils and data/shakespeare from leaf repo: https://github.com/TalwalkarLab/leaf/

3. Generate data
    #cd shakespeare
    #./preprocess.sh -s niid --sf 1.0 -k 0 -t sample -tf 0.8
    #./stats.sh

4. Preprocess data
   # copy 'language_utils.py' from leaf: models/utils/language_utils.py
   python preprocess.py


v0.0.7-1: Update output format

v0.0.7: Use the same attention

v0.0.6: Add attention aggregation

v0.0.5: Add new evaluation for shared test data

v0.0.4-2: generate individual data for each client

v0.0.4-1: Avoid using F.log_softmax before CrossEntropyLoss to prevent redundancy or errors.

v0.0.4: Add gnn_fl_cvae.py: conditional VAE

v0.0.3: Add gnn_fl_vae.py

v0.0.2-1: Update gen_data

v0.0.2: Add GNN+FL

v0.0.1: auto_labeling with GNN



