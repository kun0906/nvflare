Running with job name: 8_10_2_1
=== SLURM Environment Variables ===
SLURM_JOB_USER=kunyang
SLURM_TASKS_PER_NODE=16
SLURM_JOB_UID=149751124
SLURM_TASK_PID=3115605
SLURM_JOB_GPUS=6
SLURM_LOCALID=0
SLURM_SUBMIT_DIR=/users/kunyang/FLNLP_Dropout/rKrum_dropout
SLURMD_NODENAME=bcm-dgxa100-0020
SLURM_JOB_START_TIME=1753902678
SLURM_NODE_ALIASES=(null)
SLURM_CLUSTER_NAME=mp
SLURM_JOB_END_TIME=1753909878
SLURM_CPUS_ON_NODE=16
SLURM_JOB_CPUS_PER_NODE=16
SLURM_GPUS_ON_NODE=1
SLURM_GTIDS=0
SLURM_JOB_PARTITION=batch
SLURM_JOB_NUM_NODES=1
SLURM_JOBID=339626
SLURM_JOB_QOS=normal
SLURM_SCONTROL=/cm/shared/apps/slurm/current/bin/scontrol
SLURM_PROCID=0
SLURM_TOPOLOGY_ADDR=bcm-dgxa100-0020
SLURM_TOPOLOGY_ADDR_PATTERN=node
SLURM_MEM_PER_NODE=131072
SLURM_WORKING_CLUSTER=mp:mpcm1:6817:9984:109
SLURM_NODELIST=bcm-dgxa100-0020
SLURM_JOB_ACCOUNT=kunyang_nvflare_py31012_0001
SLURM_PRIO_PROCESS=0
SLURM_NNODES=1
SLURM_SUBMIT_HOST=slogin-01
SLURM_JOB_ID=339626
SLURM_NODEID=0
SLURM_SINFO=/cm/shared/apps/slurm/current/bin/sinfo
SLURM_CONF=/cm/shared/apps/slurm/var/etc/slurm/slurm.conf
SLURM_JOB_NAME=rkrum_8_30_1_1
SLURM_JOB_GID=999999
SLURM_JOB_NODELIST=bcm-dgxa100-0020
===================================
=== Node Information ===
===1node.sh===
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
/users/kunyang/FLNLP_Dropout/rKrum_dropout
Running on nodes: bcm-dgxa100-0020
Job ID: 339626
Running with job name: rkrum_8_30_1_1
GPUs: 1, Clients: 20, Rounds: 30, OUT_DIR: out, NODE_NAME: bcm-dgxa100-0020
SERVER_NODE: bcm-dgxa100-0020, IP: 10.211.48.23
Launching server and clients on bcm-dgxa100-0020...
===1node.sh===
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
/users/kunyang/FLNLP_Dropout/rKrum_dropout
Checking and killing existing python processes...
âœ…All python processes terminated.
ğŸš€ Starting server...
/users/kunyang/FLNLP_Dropout/rKrum_dropout
Waiting for server to start...
python3 server.py is now running.
ğŸš€ Launching client 1... cuda_idx: 0, client_idx: 1
âœ… Started ./start.sh for client site-1 with PID 3115922
ğŸš€ Launching client 2... cuda_idx: 0, client_idx: 2
âœ… Started ./start.sh for client site-2 with PID 3115923
ğŸš€ Launching client 3... cuda_idx: 0, client_idx: 3
âœ… Started ./start.sh for client site-3 with PID 3115924
ğŸš€ Launching client 4... cuda_idx: 0, client_idx: 4
âœ… Started ./start.sh for client site-4 with PID 3115925
ğŸš€ Launching client 5... cuda_idx: 0, client_idx: 5
âœ… Started ./start.sh for client site-5 with PID 3115926
ğŸš€ Launching client 6... cuda_idx: 0, client_idx: 6
âœ… Started ./start.sh for client site-6 with PID 3115927
ğŸš€ Launching client 7... cuda_idx: 0, client_idx: 7
âœ… Started ./start.sh for client site-7 with PID 3115928
ğŸš€ Launching client 8... cuda_idx: 0, client_idx: 8
âœ… Started ./start.sh for client site-8 with PID 3115929
ğŸš€ Launching client 9... cuda_idx: 0, client_idx: 9
âœ… Started ./start.sh for client site-9 with PID 3115930
ğŸš€ Launching client 10... cuda_idx: 0, client_idx: 10
âœ… Started ./start.sh for client site-10 with PID 3115931
ğŸš€ Launching client 11... cuda_idx: 0, client_idx: 11
âœ… Started ./start.sh for client site-11 with PID 3115932
ğŸš€ Launching client 12... cuda_idx: 0, client_idx: 12
âœ… Started ./start.sh for client site-12 with PID 3115933
ğŸš€ Launching client 13... cuda_idx: 0, client_idx: 13
âœ… Started ./start.sh for client site-13 with PID 3115934
ğŸš€ Launching client 14... cuda_idx: 0, client_idx: 14
âœ… Started ./start.sh for client site-14 with PID 3115935
ğŸš€ Launching client 15... cuda_idx: 0, client_idx: 15
âœ… Started ./start.sh for client site-15 with PID 3115936
ğŸš€ Launching client 16... cuda_idx: 0, client_idx: 16
âœ… Started ./start.sh for client site-16 with PID 3115937
ğŸš€ Launching client 17... cuda_idx: 0, client_idx: 17
âœ… Started ./start.sh for client site-17 with PID 3115938
ğŸš€ Launching client 18... cuda_idx: 0, client_idx: 18
âœ… Started ./start.sh for client site-18 with PID 3115939
ğŸš€ Launching client 19... cuda_idx: 0, client_idx: 19
âœ… Started ./start.sh for client site-19 with PID 3115940
ğŸš€ Launching client 20... cuda_idx: 0, client_idx: 20
âœ… Started ./start.sh for client site-20 with PID 3115941
Checking for server.py process...
ğŸ” server.py is still running.
â³ Sleeping for 100 seconds before next check...
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Checking if server.py is still running...
kunyang  3115675 33.5  0.1 14610892 3887652 ?    Sl   14:11   0:34 python3 server.py --server_ip 127.0.0.1 --workspace_dir out/ws_20_30_1_1 --num_clients 20 --num_rounds 30
â³ Sleeping for 100 seconds before next check...
Checking for server.py process...
ğŸ” server.py is still running.
â³ Sleeping for 100 seconds before next check...
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Checking if server.py is still running...
kunyang  3115675 32.2  0.1 14611284 3888696 ?    Sl   14:11   1:05 python3 server.py --server_ip 127.0.0.1 --workspace_dir out/ws_20_30_1_1 --num_clients 20 --num_rounds 30
â³ Sleeping for 100 seconds before next check...
Checking for server.py process...
ğŸ” server.py is still running.
â³ Sleeping for 100 seconds before next check...
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Checking if server.py is still running...
kunyang  3115675 34.5  0.1 14612712 3890416 ?    Rl   14:11   1:45 python3 server.py --server_ip 127.0.0.1 --workspace_dir out/ws_20_30_1_1 --num_clients 20 --num_rounds 30
â³ Sleeping for 100 seconds before next check...
Checking for server.py process...
ğŸ” server.py is still running.
â³ Sleeping for 100 seconds before next check...
hostname: bcm-dgxa100-0020
IP: 10.211.48.23
Linux bcm-dgxa100-0020 5.15.0-1046-nvidia #46-Ubuntu SMP Tue Feb 13 15:15:47 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Checking if server.py is still running...
âœ… server.py has finished. Exiting loop.
âœ… All processes terminated.
