2024-09-04 12:14:36,398 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:14:36,513 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:14:36,893 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:14:36,893 - ConnectorManager - INFO - 87447: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:14:36,895 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:13711] is starting
2024-09-04 12:14:37,396 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:13711
2024-09-04 12:14:37,397 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:14:37,399 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:14:37,404 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 12:14:37,405 - root - INFO - Server started
2024-09-04 12:14:37,430 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added secure port at 0.0.0.0:8002
2024-09-04 12:14:37,440 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 0.0.0.0:8002 <= ipv6:%5B::1%5D:52045 SSL site-1] is created: PID: 87447
2024-09-04 12:14:37,441 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00003 0.0.0.0:8002 <= ipv6:%5B::1%5D:52044 SSL site-2] is created: PID: 87447
2024-09-04 12:14:42,403 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 12:14:43,540 - ClientManager - INFO - Client: New client site-2@10.9.172.52 joined. Sent token: a8e41bad-0bd3-4276-bac6-fe926f163113.  Total clients: 1
2024-09-04 12:14:43,540 - ClientManager - INFO - Client: New client site-1@10.9.172.52 joined. Sent token: fbf31734-6128-45fe-9d55-5e803dda4004.  Total clients: 2
2024-09-04 12:26:54,865 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:26:54,965 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:26:54,993 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:26:54,993 - ConnectorManager - INFO - 88200: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:26:54,994 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:33601] is starting
2024-09-04 12:26:55,499 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:33601
2024-09-04 12:26:55,500 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:26:55,503 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:26:55,515 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 12:26:55,516 - root - INFO - Server started
2024-09-04 12:26:55,517 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 12:27:00,507 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 12:29:26,780 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:29:27,662 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:29:27,963 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:29:27,963 - ConnectorManager - INFO - 88459: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:29:27,965 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:6965] is starting
2024-09-04 12:29:28,471 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:6965
2024-09-04 12:29:28,474 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:29:28,503 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 12:29:32,130 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:29:32,144 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 12:29:32,145 - root - INFO - Server started
2024-09-04 12:29:33,484 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 12:31:37,668 - MPM - ERROR - Execute exception: AttributeError: type object 'KeyboardInterrupt' has no attribute 'close'
2024-09-04 12:31:37,670 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/PycharmProjects/nvflare/cifar10-hello-pt-10clients-2classes_demo/example_project/prod_00/server/startup/server.py", line 133, in main
    time.sleep(1.0)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10-hello-pt-10clients-2classes_demo/example_project/prod_00/server/startup/server.py", line 137, in main
    services.engine.close()
AttributeError: type object 'KeyboardInterrupt' has no attribute 'close'

2024-09-04 12:31:39,248 - MPM - WARNING - #### MPM: still running thread Thread-21 (client_cleanup)
2024-09-04 12:31:39,248 - MPM - WARNING - #### MPM: still running thread Thread-39 (_start_job_runner)
2024-09-04 12:31:39,249 - MPM - WARNING - #### MPM: still running thread Thread-40 (_job_complete_process)
2024-09-04 12:31:39,249 - MPM - INFO - MPM: Good Bye!
2024-09-04 12:31:47,841 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:31:48,647 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:31:48,743 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:31:48,743 - ConnectorManager - INFO - 88787: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:31:48,745 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:52122] is starting
2024-09-04 12:31:49,248 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:52122
2024-09-04 12:31:49,248 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:31:49,254 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 12:31:50,754 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:31:50,765 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 12:31:50,765 - root - INFO - Server started
2024-09-04 12:31:54,255 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 12:35:00,348 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:35:00,453 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:35:00,475 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:35:00,475 - ConnectorManager - INFO - 89079: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:35:00,476 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:64029] is starting
2024-09-04 12:35:00,981 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:64029
2024-09-04 12:35:00,982 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:35:00,985 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:35:01,000 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 12:35:01,001 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added secure port at 0.0.0.0:8002
2024-09-04 12:35:01,049 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/server/server_train.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 12:35:02,981 - MPM - WARNING - #### MPM: still running thread Thread-3 (client_cleanup)
2024-09-04 12:35:02,982 - MPM - WARNING - #### MPM: still running thread Thread-4 (_start_job_runner)
2024-09-04 12:35:02,982 - MPM - WARNING - #### MPM: still running thread Thread-5 (_job_complete_process)
2024-09-04 12:35:02,983 - MPM - INFO - MPM: Good Bye!
2024-09-04 12:35:04,816 - MPM - ERROR - Execute exception: AttributeError: type object 'KeyboardInterrupt' has no attribute 'close'
2024-09-04 12:35:04,820 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/PycharmProjects/nvflare/cifar10-hello-pt-10clients-2classes_demo/example_project/prod_00/server/startup/server.py", line 133, in main
    time.sleep(1.0)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10-hello-pt-10clients-2classes_demo/example_project/prod_00/server/startup/server.py", line 137, in main
    services.engine.close()
AttributeError: type object 'KeyboardInterrupt' has no attribute 'close'

2024-09-04 12:35:05,065 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:35:05,166 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:35:05,188 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:35:05,188 - ConnectorManager - INFO - 89089: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:35:05,188 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:36729] is starting
2024-09-04 12:35:05,694 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:36729
2024-09-04 12:35:05,694 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:35:05,699 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:35:05,713 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 12:35:05,714 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added secure port at 0.0.0.0:8002
2024-09-04 12:35:05,716 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/server/server_train.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 12:35:07,763 - MPM - WARNING - #### MPM: still running thread Thread-3 (client_cleanup)
2024-09-04 12:35:07,763 - MPM - WARNING - #### MPM: still running thread Thread-4 (_start_job_runner)
2024-09-04 12:35:07,763 - MPM - WARNING - #### MPM: still running thread Thread-5 (_job_complete_process)
2024-09-04 12:35:07,763 - MPM - INFO - MPM: Good Bye!
2024-09-04 12:35:10,075 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 12:35:10,175 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 12:35:10,198 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 12:35:10,199 - ConnectorManager - INFO - 89107: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 12:35:10,199 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:62618] is starting
2024-09-04 12:35:10,701 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:62618
2024-09-04 12:35:10,701 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 12:35:10,705 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 12:35:10,719 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 12:35:10,719 - root - INFO - Server started
2024-09-04 12:35:10,719 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added secure port at 0.0.0.0:8002
2024-09-04 12:35:15,706 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 12:35:16,239 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00002 0.0.0.0:8002 <= ipv6:%5B::1%5D:52369 SSL site-1] is created: PID: 89107
2024-09-04 12:35:16,296 - ClientManager - INFO - Client: New client site-1@10.9.172.52 joined. Sent token: 1a76d2ce-2e68-492a-bb7a-071437732f16.  Total clients: 1
2024-09-04 12:35:16,737 - DefaultJobScheduler - INFO - [identity=example_project, run=?]: Try to schedule job 4afed7c1-2005-4826-b96b-f5d74efbb375, get result: (scheduled).
2024-09-04 12:35:16,738 - JobRunner - INFO - [identity=example_project, run=?]: Got the job: 4afed7c1-2005-4826-b96b-f5d74efbb375 from the scheduler to run
2024-09-04 12:35:16,897 - JobRunner - INFO - [identity=example_project, run=?]: Application app_server deployed to the server for job: 4afed7c1-2005-4826-b96b-f5d74efbb375
2024-09-04 12:35:16,963 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-1 to be deployed to the clients: site-1 for run: 4afed7c1-2005-4826-b96b-f5d74efbb375
2024-09-04 12:35:17,030 - JobRunner - INFO - [identity=example_project, run=?]: Updated the schedule history of Job: 4afed7c1-2005-4826-b96b-f5d74efbb375
2024-09-04 12:35:17,055 - JobRunner - INFO - [identity=example_project, run=?]: Started run: 4afed7c1-2005-4826-b96b-f5d74efbb375 for clients: site-1
2024-09-04 12:35:17,057 - JobRunner - INFO - [identity=example_project, run=?]: Job: 4afed7c1-2005-4826-b96b-f5d74efbb375 started to run, status changed to RUNNING.
2024-09-04 12:35:18,065 - DefaultJobScheduler - INFO - [identity=example_project, run=?]: Try to schedule job ce0fc5f6-6694-4f7a-a5bc-76269196eacc, get result: (scheduled).
2024-09-04 12:35:18,065 - JobRunner - INFO - [identity=example_project, run=?]: Got the job: ce0fc5f6-6694-4f7a-a5bc-76269196eacc from the scheduler to run
2024-09-04 12:35:18,182 - JobRunner - INFO - [identity=example_project, run=?]: Application app_server deployed to the server for job: ce0fc5f6-6694-4f7a-a5bc-76269196eacc
2024-09-04 12:35:18,251 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-1 to be deployed to the clients: site-1 for run: ce0fc5f6-6694-4f7a-a5bc-76269196eacc
2024-09-04 12:35:18,343 - JobRunner - INFO - [identity=example_project, run=?]: Updated the schedule history of Job: ce0fc5f6-6694-4f7a-a5bc-76269196eacc
2024-09-04 12:35:18,359 - JobRunner - INFO - [identity=example_project, run=?]: Started run: ce0fc5f6-6694-4f7a-a5bc-76269196eacc for clients: site-1
2024-09-04 12:35:18,360 - JobRunner - INFO - [identity=example_project, run=?]: Job: ce0fc5f6-6694-4f7a-a5bc-76269196eacc started to run, status changed to RUNNING.
2024-09-04 12:35:18,818 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00003 127.0.0.1:62618 <= 127.0.0.1:52380] is created: PID: 89107
2024-09-04 12:35:19,931 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00004 127.0.0.1:62618 <= 127.0.0.1:52381] is created: PID: 89107
2024-09-04 12:35:27,324 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:27,324 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:37,351 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:37,352 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:47,377 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:47,378 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:57,405 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:35:57,407 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:07,433 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:07,434 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:17,457 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:17,461 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:27,488 - ServerEngine - WARNING - notified SJ of dead-job: job_id='ce0fc5f6-6694-4f7a-a5bc-76269196eacc'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:27,489 - ServerEngine - WARNING - notified SJ of dead-job: job_id='4afed7c1-2005-4826-b96b-f5d74efbb375'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:36:29,533 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00003 Not Connected] is closed PID: 89107
2024-09-04 12:36:29,968 - JobRunner - INFO - [identity=example_project, run=?]: Try to abort job (4afed7c1-2005-4826-b96b-f5d74efbb375) on clients ...
2024-09-04 12:36:30,584 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00004 Not Connected] is closed PID: 89107
2024-09-04 12:36:31,053 - JobRunner - INFO - [identity=example_project, run=?]: Try to abort job (ce0fc5f6-6694-4f7a-a5bc-76269196eacc) on clients ...
2024-09-04 12:42:53,560 - DefaultJobScheduler - INFO - [identity=example_project, run=?]: Try to schedule job a621efb8-9713-44e9-8df5-7b8e772e2280, get result: (scheduled).
2024-09-04 12:42:53,561 - JobRunner - INFO - [identity=example_project, run=?]: Got the job: a621efb8-9713-44e9-8df5-7b8e772e2280 from the scheduler to run
2024-09-04 12:42:53,697 - JobRunner - INFO - [identity=example_project, run=?]: Application app_server deployed to the server for job: a621efb8-9713-44e9-8df5-7b8e772e2280
2024-09-04 12:42:53,768 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-1 to be deployed to the clients: site-1 for run: a621efb8-9713-44e9-8df5-7b8e772e2280
2024-09-04 12:42:53,934 - JobRunner - INFO - [identity=example_project, run=?]: Updated the schedule history of Job: a621efb8-9713-44e9-8df5-7b8e772e2280
2024-09-04 12:42:53,993 - JobRunner - INFO - [identity=example_project, run=?]: Started run: a621efb8-9713-44e9-8df5-7b8e772e2280 for clients: site-1
2024-09-04 12:42:53,995 - JobRunner - INFO - [identity=example_project, run=?]: Job: a621efb8-9713-44e9-8df5-7b8e772e2280 started to run, status changed to RUNNING.
2024-09-04 12:42:55,980 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00005 127.0.0.1:62618 <= 127.0.0.1:52440] is created: PID: 89107
2024-09-04 12:43:08,494 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:43:18,514 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:43:28,542 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:43:38,565 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:43:48,590 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:43:58,616 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:44:08,646 - ServerEngine - WARNING - notified SJ of dead-job: job_id='a621efb8-9713-44e9-8df5-7b8e772e2280'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:44:12,644 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00005 Not Connected] is closed PID: 89107
2024-09-04 12:44:13,805 - JobRunner - INFO - [identity=example_project, run=?]: Try to abort job (a621efb8-9713-44e9-8df5-7b8e772e2280) on clients ...
2024-09-04 12:44:24,816 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00006 0.0.0.0:8002 <= ipv6:%5B::1%5D:52453 SSL site-2] is created: PID: 89107
2024-09-04 12:44:25,170 - ClientManager - INFO - Client: New client site-2@10.9.172.52 joined. Sent token: c0158813-acf7-45e0-9e28-bda9babdef5b.  Total clients: 2
2024-09-04 12:44:39,553 - DefaultJobScheduler - INFO - [identity=example_project, run=?]: Try to schedule job 335d7e74-fecf-4fd9-b0bd-871867d0f1d6, get result: (scheduled).
2024-09-04 12:44:39,554 - JobRunner - INFO - [identity=example_project, run=?]: Got the job: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6 from the scheduler to run
2024-09-04 12:44:39,704 - JobRunner - INFO - [identity=example_project, run=?]: Application app_server deployed to the server for job: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6
2024-09-04 12:44:39,786 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-1 to be deployed to the clients: site-1 for run: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6
2024-09-04 12:44:39,942 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-2 to be deployed to the clients: site-2 for run: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6
2024-09-04 12:44:39,968 - JobRunner - INFO - [identity=example_project, run=?]: Updated the schedule history of Job: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6
2024-09-04 12:44:40,003 - JobRunner - INFO - [identity=example_project, run=?]: Started run: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6 for clients: site-1,site-2
2024-09-04 12:44:40,008 - JobRunner - INFO - [identity=example_project, run=?]: Job: 335d7e74-fecf-4fd9-b0bd-871867d0f1d6 started to run, status changed to RUNNING.
2024-09-04 12:44:42,229 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00007 127.0.0.1:62618 <= 127.0.0.1:52465] is created: PID: 89107
2024-09-04 12:44:46,223 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:44:48,737 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:44:56,252 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:44:58,761 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:06,281 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:45:08,788 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:16,422 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:45:18,807 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:26,444 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:45:28,823 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:36,475 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:45:38,849 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:46,496 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-2'; reason='missing job on client'
2024-09-04 12:45:48,878 - ServerEngine - WARNING - notified SJ of dead-job: job_id='335d7e74-fecf-4fd9-b0bd-871867d0f1d6'; client_name='site-1'; reason='missing job on client'
2024-09-04 12:45:52,910 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00007 Not Connected] is closed PID: 89107
2024-09-04 12:45:53,235 - JobRunner - INFO - [identity=example_project, run=?]: Try to abort job (335d7e74-fecf-4fd9-b0bd-871867d0f1d6) on clients ...
2024-09-04 12:46:22,533 - DefaultJobScheduler - INFO - [identity=example_project, run=?]: Try to schedule job c237095d-43f6-473b-a930-feb0fe2a41df, get result: (scheduled).
2024-09-04 12:46:22,534 - JobRunner - INFO - [identity=example_project, run=?]: Got the job: c237095d-43f6-473b-a930-feb0fe2a41df from the scheduler to run
2024-09-04 12:46:22,673 - JobRunner - INFO - [identity=example_project, run=?]: Application app_server deployed to the server for job: c237095d-43f6-473b-a930-feb0fe2a41df
2024-09-04 12:46:22,732 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-1 to be deployed to the clients: site-1 for run: c237095d-43f6-473b-a930-feb0fe2a41df
2024-09-04 12:46:22,787 - JobRunner - INFO - [identity=example_project, run=?]: App app_site-2 to be deployed to the clients: site-2 for run: c237095d-43f6-473b-a930-feb0fe2a41df
2024-09-04 12:46:22,817 - JobRunner - INFO - [identity=example_project, run=?]: Updated the schedule history of Job: c237095d-43f6-473b-a930-feb0fe2a41df
2024-09-04 12:46:22,835 - JobRunner - INFO - [identity=example_project, run=?]: Started run: c237095d-43f6-473b-a930-feb0fe2a41df for clients: site-1,site-2
2024-09-04 12:46:22,837 - JobRunner - INFO - [identity=example_project, run=?]: Job: c237095d-43f6-473b-a930-feb0fe2a41df started to run, status changed to RUNNING.
2024-09-04 12:46:25,357 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00008 127.0.0.1:62618 <= 127.0.0.1:52496] is created: PID: 89107
2024-09-04 12:46:26,113 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00009 0.0.0.0:8002 <= ipv6:%5B::1%5D:52499 SSL site-2] is created: PID: 89107
2024-09-04 12:46:26,114 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00010 0.0.0.0:8002 <= ipv6:%5B::1%5D:52500 SSL site-1] is created: PID: 89107
2024-09-04 12:46:46,933 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00009 Not Connected] is closed PID: 89107
2024-09-04 12:46:46,934 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00010 Not Connected] is closed PID: 89107
2024-09-04 12:46:47,939 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connection [CN00008 Not Connected] is closed PID: 89107
2024-09-04 17:02:52,522 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:02:52,522 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:02:52,526 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:02:52,526 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:02:52,526 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:02:52,526 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:02:52,527 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:02:52,527 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:02:52,527 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:02:52,527 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:02:52,527 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:02:52,527 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:02:52,645 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:02:52,645 - Cell - DEBUG - calling core_cell start
2024-09-04 17:02:52,645 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:02:52,645 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:02:52,814 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:02:52,814 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:02:52,815 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:02:52,859 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:02:52,859 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:02:52,859 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:02:52,859 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:02:52,869 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:02:52,869 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:02:52,869 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:02:52,869 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:02:52,877 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:02:52,877 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:02:52,877 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:02:52,878 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:02:52,878 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:02:52,878 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:02:52,878 - ConnectorManager - INFO - 21042: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:02:52,879 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:02:52,879 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:19005] is created
2024-09-04 17:02:52,879 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:19005] is starting
2024-09-04 17:02:52,879 - ConnectorManager - DEBUG - 21042: ############ dynamic listener at tcp://localhost:19005
2024-09-04 17:02:53,381 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:19005
2024-09-04 17:02:53,381 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:02:53,382 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:02:53,382 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:02:53,382 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x1194b26b0>>}
2024-09-04 17:02:53,382 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:02:53,382 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x1194b26b0>>}
2024-09-04 17:02:53,382 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:02:53,383 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x1194b26b0>>}
2024-09-04 17:02:53,383 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:02:53,383 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x1194b26b0>>}
2024-09-04 17:02:53,383 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:02:53,383 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x1194b26b0>>}
2024-09-04 17:02:53,383 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:02:53,383 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:02:53,388 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:02:53,407 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:02:53,407 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:02:53,428 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:02:53,428 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:02:54,933 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:02:54,934 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:02:54,934 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:02:54,934 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:02:54,935 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:02:54,935 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:02:54,935 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:02:54,935 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:02:55,384 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:19005] has stopped
2024-09-04 17:02:55,475 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:02:55,475 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:02:55,475 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:02:55,475 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:02:55,475 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:02:55,475 - MPM - WARNING - #### MPM: still running thread Thread-3 (client_cleanup)
2024-09-04 17:02:55,475 - MPM - WARNING - #### MPM: still running thread Thread-4 (_start_job_runner)
2024-09-04 17:02:55,475 - MPM - WARNING - #### MPM: still running thread Thread-5 (_job_complete_process)
2024-09-04 17:02:55,475 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:07:19,265 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:07:19,265 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:07:19,266 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:07:19,267 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:07:19,267 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:07:19,267 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:07:19,267 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:07:19,267 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:07:19,267 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:07:19,267 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:07:19,267 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:07:19,267 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:07:19,365 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:07:19,366 - Cell - DEBUG - calling core_cell start
2024-09-04 17:07:19,366 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:07:19,366 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:07:19,385 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:07:19,385 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:07:19,385 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:07:19,392 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:07:19,392 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:07:19,392 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:07:19,392 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:07:19,393 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:07:19,393 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:07:19,393 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:07:19,393 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:07:19,394 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:07:19,394 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:07:19,394 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:07:19,394 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:07:19,394 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:07:19,394 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:07:19,394 - ConnectorManager - INFO - 21494: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:07:19,395 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:07:19,395 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:18131] is created
2024-09-04 17:07:19,395 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:18131] is starting
2024-09-04 17:07:19,395 - ConnectorManager - DEBUG - 21494: ############ dynamic listener at tcp://localhost:18131
2024-09-04 17:07:19,900 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:18131
2024-09-04 17:07:19,901 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:07:19,903 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:07:19,904 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:19,905 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119cc66b0>>}
2024-09-04 17:07:19,905 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:19,905 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119cc66b0>>}
2024-09-04 17:07:19,905 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:19,906 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119cc66b0>>}
2024-09-04 17:07:19,906 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:19,906 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119cc66b0>>}
2024-09-04 17:07:19,906 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:19,906 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119cc66b0>>}
2024-09-04 17:07:19,906 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:19,908 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:07:19,917 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:07:19,917 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:07:19,918 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:07:19,921 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:07:19,922 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:07:21,427 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:07:21,427 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:07:21,427 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:07:21,427 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:07:21,427 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:07:21,427 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:07:21,427 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:07:21,428 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:07:21,447 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:07:21,901 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:18131] has stopped
2024-09-04 17:07:21,901 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:07:21,901 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:07:21,901 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:07:24,911 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 17:07:24,912 - SimpleJobDefManager - DEBUG - [identity=example_project, run=?]: objects to scan: 5
2024-09-04 17:07:24,989 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:30,088 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:35,175 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:40,257 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:45,359 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:50,434 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:50,855 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:07:53,975 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:07:53,985 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:07:53,985 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:07:53,986 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:07:53,986 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:07:53,987 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:07:53,987 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:07:53,987 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:07:53,987 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:07:53,987 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:07:53,987 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:07:54,104 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:07:54,104 - Cell - DEBUG - calling core_cell start
2024-09-04 17:07:54,104 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:07:54,104 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:07:54,272 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:07:54,273 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:07:54,273 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:07:54,318 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:07:54,318 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:07:54,318 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:07:54,319 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:07:54,330 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:07:54,330 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:07:54,331 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:07:54,331 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:07:54,340 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:07:54,340 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:07:54,341 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:07:54,341 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:07:54,342 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:07:54,342 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:07:54,342 - ConnectorManager - INFO - 21518: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:07:54,344 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:07:54,344 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:40522] is created
2024-09-04 17:07:54,345 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:40522] is starting
2024-09-04 17:07:54,345 - ConnectorManager - DEBUG - 21518: ############ dynamic listener at tcp://localhost:40522
2024-09-04 17:07:54,851 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:40522
2024-09-04 17:07:54,852 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:07:54,855 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:07:54,856 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:54,856 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119ade500>>}
2024-09-04 17:07:54,857 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:54,857 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119ade500>>}
2024-09-04 17:07:54,857 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:54,858 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119ade500>>}
2024-09-04 17:07:54,858 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:54,858 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119ade500>>}
2024-09-04 17:07:54,858 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:54,858 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x119ade500>>}
2024-09-04 17:07:54,859 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:07:54,881 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:07:54,881 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:07:55,523 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:07:59,942 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:00,621 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:02,455 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:08:02,469 - MPM - ERROR - Execute exception: AttributeError: type object 'OSError' has no attribute 'close'
2024-09-04 17:08:02,474 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 137, in main
    services.engine.close()
AttributeError: type object 'OSError' has no attribute 'close'

2024-09-04 17:08:02,474 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:08:03,979 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:08:03,980 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:08:03,980 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:08:03,980 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:08:03,981 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:08:03,981 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:08:03,981 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:08:03,981 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:08:03,983 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:08:04,378 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:40522] has stopped
2024-09-04 17:08:04,380 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:08:04,381 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:08:04,381 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:08:04,381 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:04,381 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:04,381 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:04,381 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:04,382 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:08:04,382 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:08:04,382 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:08:04,382 - MPM - WARNING - #### MPM: still running thread Thread-24 (client_cleanup)
2024-09-04 17:08:04,383 - MPM - WARNING - #### MPM: still running thread Thread-42 (_start_job_runner)
2024-09-04 17:08:04,383 - MPM - WARNING - #### MPM: still running thread Thread-43 (_job_complete_process)
2024-09-04 17:08:04,383 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:08:05,720 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:10,800 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:15,895 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:20,105 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:08:20,105 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:08:20,106 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:08:20,106 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:08:20,106 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:08:20,107 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:08:20,107 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:08:20,107 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:08:20,107 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:08:20,107 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:08:20,107 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:08:20,107 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:08:20,205 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:08:20,206 - Cell - DEBUG - calling core_cell start
2024-09-04 17:08:20,206 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:08:20,206 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:08:20,223 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:08:20,223 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:08:20,224 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:08:20,230 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:08:20,230 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:08:20,230 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:08:20,230 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:08:20,231 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:08:20,231 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:08:20,231 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:08:20,231 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:08:20,232 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:08:20,232 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:08:20,233 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:08:20,233 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:08:20,233 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:08:20,233 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:08:20,233 - ConnectorManager - INFO - 21601: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:08:20,233 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:08:20,234 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:2914] is created
2024-09-04 17:08:20,234 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:2914] is starting
2024-09-04 17:08:20,234 - ConnectorManager - DEBUG - 21601: ############ dynamic listener at tcp://localhost:2914
2024-09-04 17:08:20,735 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:2914
2024-09-04 17:08:20,736 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:08:20,736 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:08:20,737 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:20,737 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11950e6b0>>}
2024-09-04 17:08:20,737 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:20,737 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11950e6b0>>}
2024-09-04 17:08:20,737 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:20,737 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11950e6b0>>}
2024-09-04 17:08:20,737 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:20,737 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11950e6b0>>}
2024-09-04 17:08:20,737 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:20,738 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11950e6b0>>}
2024-09-04 17:08:20,738 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:20,738 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:08:20,745 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:08:20,746 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:08:20,746 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:08:20,748 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:08:20,748 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:08:20,975 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:22,254 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:08:22,254 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:08:22,255 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:08:22,255 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:08:22,255 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:08:22,255 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:08:22,256 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:08:22,256 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:08:22,257 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:08:22,738 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:2914] has stopped
2024-09-04 17:08:22,739 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:08:22,740 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:08:22,740 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:08:22,740 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:22,740 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:22,740 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:22,741 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:22,741 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:08:22,741 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:08:22,741 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:08:22,741 - MPM - WARNING - #### MPM: still running thread Thread-3 (client_cleanup)
2024-09-04 17:08:22,741 - MPM - WARNING - #### MPM: still running thread Thread-4 (_start_job_runner)
2024-09-04 17:08:22,742 - MPM - WARNING - #### MPM: still running thread Thread-5 (_job_complete_process)
2024-09-04 17:08:22,742 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:08:26,074 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:31,154 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:35,522 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:08:35,522 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:08:35,524 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:08:35,524 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:08:35,524 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:08:35,524 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:08:35,524 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:08:35,525 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:08:35,525 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:08:35,525 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:08:35,525 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:08:35,525 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:08:35,624 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:08:35,624 - Cell - DEBUG - calling core_cell start
2024-09-04 17:08:35,624 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:08:35,625 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:08:35,645 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:08:35,645 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:08:35,645 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:08:35,653 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:08:35,653 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:08:35,653 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:08:35,654 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:08:35,655 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:08:35,655 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:08:35,655 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:08:35,655 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:08:35,656 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:08:35,657 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:08:35,657 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:08:35,657 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:08:35,657 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:08:35,657 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:08:35,657 - ConnectorManager - INFO - 21627: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:08:35,658 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:08:35,659 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:15330] is created
2024-09-04 17:08:35,659 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:15330] is starting
2024-09-04 17:08:35,659 - ConnectorManager - DEBUG - 21627: ############ dynamic listener at tcp://localhost:15330
2024-09-04 17:08:36,164 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:15330
2024-09-04 17:08:36,165 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:08:36,169 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:08:36,170 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:36,170 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c46c3d0>>}
2024-09-04 17:08:36,171 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:36,172 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c46c3d0>>}
2024-09-04 17:08:36,173 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:36,174 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c46c3d0>>}
2024-09-04 17:08:36,174 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:36,174 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c46c3d0>>}
2024-09-04 17:08:36,175 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:36,175 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c46c3d0>>}
2024-09-04 17:08:36,181 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:08:36,183 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:08:36,185 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:08:36,193 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:08:36,194 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:08:36,198 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:08:36,198 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:08:36,237 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:37,704 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:08:37,705 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:08:37,706 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:08:37,706 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:08:37,706 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:08:37,706 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:08:37,706 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:08:37,707 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:08:37,708 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:08:38,171 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:15330] has stopped
2024-09-04 17:08:38,173 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:08:38,173 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:08:38,173 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:08:38,174 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:38,174 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:38,174 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:08:38,174 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:08:38,174 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:08:38,175 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:08:38,175 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:08:38,176 - MPM - WARNING - #### MPM: still running thread Thread-7 (client_cleanup)
2024-09-04 17:08:38,176 - MPM - WARNING - #### MPM: still running thread Thread-8 (_start_job_runner)
2024-09-04 17:08:38,176 - MPM - WARNING - #### MPM: still running thread Thread-9 (_job_complete_process)
2024-09-04 17:08:38,177 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:08:41,343 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:46,438 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:51,517 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:08:56,619 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:09:05,525 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:09:05,525 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:09:05,527 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:09:05,527 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:09:05,527 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:09:05,527 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:09:05,527 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:09:05,528 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:09:05,528 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:09:05,528 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:09:05,528 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:09:05,528 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:09:05,628 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:09:05,628 - Cell - DEBUG - calling core_cell start
2024-09-04 17:09:05,628 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:09:05,628 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:09:05,649 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:09:05,650 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:09:05,650 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:09:05,658 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:09:05,658 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:09:05,658 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:09:05,658 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:09:05,660 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:09:05,660 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:09:05,660 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:09:05,660 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:09:05,661 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:09:05,661 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:09:05,662 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:09:05,662 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:09:05,662 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:09:05,662 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:09:05,662 - ConnectorManager - INFO - 21807: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:09:05,663 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:09:05,663 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:57104] is created
2024-09-04 17:09:05,663 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:57104] is starting
2024-09-04 17:09:05,664 - ConnectorManager - DEBUG - 21807: ############ dynamic listener at tcp://localhost:57104
2024-09-04 17:09:06,169 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:57104
2024-09-04 17:09:06,171 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:09:06,175 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:09:06,177 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:09:06,178 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11bf083d0>>}
2024-09-04 17:09:06,181 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:06,182 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11bf083d0>>}
2024-09-04 17:09:06,183 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:06,184 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11bf083d0>>}
2024-09-04 17:09:06,185 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:06,186 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11bf083d0>>}
2024-09-04 17:09:06,186 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:06,186 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11bf083d0>>}
2024-09-04 17:09:06,187 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:06,189 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:09:06,201 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:09:06,201 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:09:06,202 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:09:06,205 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:09:06,205 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:09:07,712 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:09:07,713 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:09:07,713 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:09:07,713 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:09:07,714 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:09:07,714 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:09:07,714 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:09:07,715 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:09:07,717 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:09:08,175 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:57104] has stopped
2024-09-04 17:09:08,176 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:09:08,176 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:09:08,176 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:09:08,176 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:09:08,176 - MPM - WARNING - #### MPM: still running thread Thread-7 (client_cleanup)
2024-09-04 17:09:08,176 - MPM - WARNING - #### MPM: still running thread Thread-8 (_start_job_runner)
2024-09-04 17:09:08,176 - MPM - WARNING - #### MPM: still running thread Thread-9 (_job_complete_process)
2024-09-04 17:09:08,177 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:09:58,386 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:09:58,386 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:09:58,388 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:09:58,388 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:09:58,388 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:09:58,389 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:09:58,389 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:09:58,389 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:09:58,389 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:09:58,389 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:09:58,389 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:09:58,389 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:09:58,489 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:09:58,489 - Cell - DEBUG - calling core_cell start
2024-09-04 17:09:58,489 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:09:58,489 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:09:58,511 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:09:58,511 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:09:58,511 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:09:58,519 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:09:58,519 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:09:58,519 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:09:58,519 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:09:58,521 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:09:58,521 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:09:58,521 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:09:58,521 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:09:58,522 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:09:58,522 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:09:58,523 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:09:58,523 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:09:58,523 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:09:58,523 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:09:58,523 - ConnectorManager - INFO - 21913: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:09:58,524 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:09:58,524 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:47790] is created
2024-09-04 17:09:58,524 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:47790] is starting
2024-09-04 17:09:58,525 - ConnectorManager - DEBUG - 21913: ############ dynamic listener at tcp://localhost:47790
2024-09-04 17:09:59,030 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:47790
2024-09-04 17:09:59,031 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:09:59,036 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:09:59,037 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:09:59,037 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c6b03d0>>}
2024-09-04 17:09:59,038 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:59,039 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c6b03d0>>}
2024-09-04 17:09:59,039 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:59,040 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c6b03d0>>}
2024-09-04 17:09:59,040 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:59,041 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c6b03d0>>}
2024-09-04 17:09:59,041 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:59,041 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c6b03d0>>}
2024-09-04 17:09:59,042 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:09:59,045 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:09:59,058 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:09:59,059 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:09:59,059 - MPM - ERROR - Execute exception: OSError: [Errno 48] Address already in use
2024-09-04 17:09:59,063 - MPM - ERROR - Traceback (most recent call last):
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/f3/mpm.py", line 154, in run
    rc = main_func(**kwargs)
  File "/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.py", line 113, in main
    admin_server = create_admin_server(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/app/utils.py", line 81, in create_admin_server
    admin_server = FedAdminServer(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/private/fed/server/admin.py", line 175, in __init__
    AdminServer.__init__(
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/site-packages/nvflare/fuel/hci/server/hci.py", line 180, in __init__
    self.server_bind()
  File "/Users/49751124/miniconda3/envs/nvflare/lib/python3.10/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2024-09-04 17:09:59,063 - MPM - DEBUG - =========== MPM: Shutting down. Starting cleanup ...
2024-09-04 17:10:00,565 - MPM - DEBUG - MPM: cleanup round 1
2024-09-04 17:10:00,565 - MPM - DEBUG - MPM: calling cleanup CB stream_shutdown
2024-09-04 17:10:00,565 - MPM - DEBUG - MPM: finished cleanup CB stream_shutdown
2024-09-04 17:10:00,566 - MPM - DEBUG - MPM: calling cleanup CB method
2024-09-04 17:10:00,566 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:10:00,566 - Cell - DEBUG - calling core_cell stop
2024-09-04 17:10:00,566 - CoreCell - DEBUG - server: Stopping Cell
2024-09-04 17:10:00,566 - nvflare.fuel.f3.sfm.heartbeat_monitor - DEBUG - Heartbeat monitor stopped
2024-09-04 17:10:00,567 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] has stopped
2024-09-04 17:10:01,041 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:47790] has stopped
2024-09-04 17:10:01,042 - nvflare.fuel.f3.communicator - DEBUG - Communicator endpoint: server has stopped
2024-09-04 17:10:01,043 - CoreCell - DEBUG - server: cell stopped!
2024-09-04 17:10:01,043 - MPM - DEBUG - MPM: finished cleanup CB method
2024-09-04 17:10:01,043 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:10:01,044 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:10:01,044 - MPM - DEBUG - MPM: calling cleanup CB close
2024-09-04 17:10:01,044 - MPM - DEBUG - MPM: finished cleanup CB close
2024-09-04 17:10:01,044 - MPM - DEBUG - MPM: finished cleanup round 1
2024-09-04 17:10:01,045 - MPM - DEBUG - MPM: Cleanup Finished!
2024-09-04 17:10:01,045 - MPM - DEBUG - =========== MPM: checking running threads
2024-09-04 17:10:01,045 - MPM - WARNING - #### MPM: still running thread Thread-7 (client_cleanup)
2024-09-04 17:10:01,046 - MPM - WARNING - #### MPM: still running thread Thread-8 (_start_job_runner)
2024-09-04 17:10:01,046 - MPM - WARNING - #### MPM: still running thread Thread-9 (_job_complete_process)
2024-09-04 17:10:01,046 - MPM - INFO - MPM: Good Bye!
2024-09-04 17:11:25,363 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - server heartbeat timeout set to 600
2024-09-04 17:11:25,363 - ConfigFactory - DEBUG - search file basename:'comm_config', search dir = /Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var max_message_size from env
2024-09-04 17:11:25,365 - CoreCell - DEBUG - server: max_msg_size=2144337904
2024-09-04 17:11:25,365 - CoreCell - DEBUG - Creating Cell: server
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var heartbeat_interval from env
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var backbone_conn_gen from env
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var internal_conn_scheme from env
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var allow_adhoc_conns from env
2024-09-04 17:11:25,365 - nvflare.fuel.utils.config_service - DEBUG - got var adhoc_conn_scheme from env
2024-09-04 17:11:25,365 - ConnectorManager - DEBUG - internal scheme=tcp, resources={'host': 'localhost'}
2024-09-04 17:11:25,365 - ConnectorManager - DEBUG - adhoc scheme=tcp, resources={}
2024-09-04 17:11:25,463 - Cell - DEBUG - __getattr__: args=(), kwargs={}
2024-09-04 17:11:25,464 - Cell - DEBUG - calling core_cell start
2024-09-04 17:11:25,464 - CoreCell - INFO - server: creating listener on grpc://0:8002
2024-09-04 17:11:25,464 - CoreCell - DEBUG - server: trying create ext listener: url=grpc://0:8002
2024-09-04 17:11:25,487 - nvflare.fuel.utils.config_service - DEBUG - got var use_aio_grpc from env
2024-09-04 17:11:25,487 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpc
2024-09-04 17:11:25,487 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioGrpcDriver is registered for agrpcs
2024-09-04 17:11:25,495 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for http
2024-09-04 17:11:25,495 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for https
2024-09-04 17:11:25,495 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for ws
2024-09-04 17:11:25,496 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioHttpDriver is registered for wss
2024-09-04 17:11:25,497 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for atcp
2024-09-04 17:11:25,497 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver AioTcpDriver is registered for satcp
2024-09-04 17:11:25,497 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for tcp
2024-09-04 17:11:25,497 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver TcpDriver is registered for stcp
2024-09-04 17:11:25,498 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpc
2024-09-04 17:11:25,498 - nvflare.fuel.f3.drivers.driver_manager - DEBUG - Driver GrpcDriver is registered for grpcs
2024-09-04 17:11:25,499 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:11:25,499 - nvflare.fuel.f3.drivers.grpc_driver.GrpcDriver - DEBUG - GRPC Config: max_workers=100, options=[('grpc.max_send_message_length', 2145386496), ('grpc.max_receive_message_length', 2145386496)]
2024-09-04 17:11:25,499 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00001 PASSIVE grpc://0:8002] is created
2024-09-04 17:11:25,499 - CoreCell - INFO - server: created backbone external listener for grpc://0:8002
2024-09-04 17:11:25,499 - ConnectorManager - INFO - 22113: Try start_listener Listener resources: {'secure': False, 'host': 'localhost'}
2024-09-04 17:11:25,500 - nvflare.fuel.utils.config_service - DEBUG - got var comm_driver_path from env
2024-09-04 17:11:25,501 - nvflare.fuel.f3.sfm.conn_manager - DEBUG - Connector [CH00002 PASSIVE tcp://0:25160] is created
2024-09-04 17:11:25,501 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 PASSIVE tcp://0:25160] is starting
2024-09-04 17:11:25,501 - ConnectorManager - DEBUG - 22113: ############ dynamic listener at tcp://localhost:25160
2024-09-04 17:11:26,006 - CoreCell - INFO - server: created backbone internal listener for tcp://localhost:25160
2024-09-04 17:11:26,007 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 PASSIVE grpc://0:8002] is starting
2024-09-04 17:11:26,010 - nvflare.fuel.f3.communicator - DEBUG - Communicator for local endpoint: server is started
2024-09-04 17:11:26,011 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:26,011 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'register', 'cb': <bound method FederatedServer.register_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c05c3d0>>}
2024-09-04 17:11:26,012 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:11:26,012 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'quit', 'cb': <bound method FederatedServer.quit_client of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c05c3d0>>}
2024-09-04 17:11:26,013 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:11:26,013 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'heart_beat', 'cb': <bound method FederatedServer.client_heartbeat of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c05c3d0>>}
2024-09-04 17:11:26,013 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:11:26,014 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'task', 'topic': 'report_job_failure', 'cb': <bound method FederatedServer.process_job_failure of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c05c3d0>>}
2024-09-04 17:11:26,015 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:11:26,015 - Cell - DEBUG - __getattr__: args=(), kwargs={'channel': 'server_parent_listener', 'topic': '*', 'cb': <bound method FederatedServer._listen_command of <nvflare.private.fed.server.fed_server.FederatedServer object at 0x11c05c3d0>>}
2024-09-04 17:11:26,016 - Cell - DEBUG - calling core_cell register_request_cb
2024-09-04 17:11:26,019 - nvflare.private.fed.app.deployer.server_deployer.ServerDeployer - INFO - deployed FLARE Server.
2024-09-04 17:11:26,033 - nvflare.fuel.f3.drivers.grpc_driver.Server - DEBUG - SERVER: connector params: {'url': 'grpc://0:8002', 'scheme': 'grpc', 'host': '', 'port': '8002', 'path': '', 'params': '', 'query': '', 'frag': '', 'ca_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/rootCA.pem', 'server_cert': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.crt', 'server_key': '/Users/49751124/PycharmProjects/nvflare/cifar10_demo/poc/example_project/prod_00/server/startup/server.key', <DriverParams.SECURE: 'secure'>: 'trueorg=nvidiaconfig_folder=config'}
2024-09-04 17:11:26,034 - nvflare.fuel.f3.drivers.grpc_driver.Server - INFO - added insecure port at 0.0.0.0:8002
2024-09-04 17:11:26,034 - nvflare.fuel.hci.server.hci - INFO - Starting Admin Server localhost on Port 8003
2024-09-04 17:11:26,034 - root - INFO - Server started
2024-09-04 17:11:31,022 - ServerState - INFO - Got the primary sp: localhost fl_port: 8002 SSID: ebc6125d-0a56-4688-9b08-355fe9e4d61a. Turning to hot.
2024-09-04 17:11:31,027 - SimpleJobDefManager - DEBUG - [identity=example_project, run=?]: objects to scan: 5
2024-09-04 17:11:31,101 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:36,199 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:41,297 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:46,398 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:51,483 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:11:56,570 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:01,664 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:06,755 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:11,859 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:16,942 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:22,033 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:27,121 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:32,207 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:37,297 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:42,383 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:47,475 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:52,563 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:12:57,662 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:02,749 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:07,839 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:12,929 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:18,002 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:23,100 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:28,194 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:33,284 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:38,396 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:43,493 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:48,569 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:53,671 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:13:58,764 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:03,860 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:08,945 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:14,036 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:19,126 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:24,227 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:29,306 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:34,406 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:39,498 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:44,592 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:49,689 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:54,781 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:14:59,866 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:04,957 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:10,052 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:15,151 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:20,236 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:25,333 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:30,459 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:35,554 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:40,649 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:45,746 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:50,833 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:15:55,927 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:01,011 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:06,096 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:11,165 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:16,266 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:21,356 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:26,436 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:31,504 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:36,588 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:41,679 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:46,771 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:51,866 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:16:56,964 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:02,054 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:07,137 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:12,227 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:17,314 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:22,400 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:27,495 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:32,588 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:37,685 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:42,773 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:47,866 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:52,943 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:17:58,034 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:03,137 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:08,240 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:13,328 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:18,428 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:23,516 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:28,599 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:33,694 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:38,768 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:43,857 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:48,947 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:54,029 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:18:59,121 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:04,221 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:09,321 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:14,409 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:19,483 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:24,573 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:29,682 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:34,774 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:39,865 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:44,958 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:50,037 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:19:55,130 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:00,231 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:05,328 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:10,423 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:15,516 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:20,612 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:25,712 - FederatedServer - DEBUG - trying to remove dead clients .......
2024-09-04 17:20:30,802 - FederatedServer - DEBUG - trying to remove dead clients .......
